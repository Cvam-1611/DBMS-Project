{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DBMS_PROJECT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0gsrKlhc4OM",
        "outputId": "a4bda11f-b2a9-48ed-8c8f-27cffe5b7b80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv4f_ZToYe22"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy  as np\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ8r6Fy5Ye26"
      },
      "source": [
        "\n",
        "training_documents=pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/train.tsv',delimiter=\"\\t\")\n",
        "testing_documents=pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/test.tsv',delimiter=\"\\t\")\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp9ONAM2Ye26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "45dc6e99-bfbd-48ef-a300-7e2688ec7d09"
      },
      "source": [
        "training_documents"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156055</th>\n",
              "      <td>156056</td>\n",
              "      <td>8544</td>\n",
              "      <td>Hearst 's</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156056</th>\n",
              "      <td>156057</td>\n",
              "      <td>8544</td>\n",
              "      <td>forced avuncular chortles</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156057</th>\n",
              "      <td>156058</td>\n",
              "      <td>8544</td>\n",
              "      <td>avuncular chortles</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156058</th>\n",
              "      <td>156059</td>\n",
              "      <td>8544</td>\n",
              "      <td>avuncular</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156059</th>\n",
              "      <td>156060</td>\n",
              "      <td>8544</td>\n",
              "      <td>chortles</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>156060 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  ...  Sentiment\n",
              "0              1  ...          1\n",
              "1              2  ...          2\n",
              "2              3  ...          2\n",
              "3              4  ...          2\n",
              "4              5  ...          2\n",
              "...          ...  ...        ...\n",
              "156055    156056  ...          2\n",
              "156056    156057  ...          1\n",
              "156057    156058  ...          3\n",
              "156058    156059  ...          2\n",
              "156059    156060  ...          2\n",
              "\n",
              "[156060 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5x90xY_Ye28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9aa0d220-eb44-47f6-e6a3-01f61a0b7450"
      },
      "source": [
        "testing_documents"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66287</th>\n",
              "      <td>222348</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded , predictable scenario .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66288</th>\n",
              "      <td>222349</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded , predictable scenario</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66289</th>\n",
              "      <td>222350</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66290</th>\n",
              "      <td>222351</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66291</th>\n",
              "      <td>222352</td>\n",
              "      <td>11855</td>\n",
              "      <td>predictable scenario</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66292 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       PhraseId  SentenceId                                             Phrase\n",
              "0        156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1        156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2        156063        8545                                                 An\n",
              "3        156064        8545  intermittently pleasing but mostly routine effort\n",
              "4        156065        8545         intermittently pleasing but mostly routine\n",
              "...         ...         ...                                                ...\n",
              "66287    222348       11855             A long-winded , predictable scenario .\n",
              "66288    222349       11855               A long-winded , predictable scenario\n",
              "66289    222350       11855                                    A long-winded ,\n",
              "66290    222351       11855                                      A long-winded\n",
              "66291    222352       11855                               predictable scenario\n",
              "\n",
              "[66292 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udsAUNsGYe29",
        "outputId": "7973f2ae-d6d2-4380-f1bd-b9aa5b33e7b8"
      },
      "source": [
        "phrase=training_documents.iloc[:,2]\n",
        "test_phrase=testing_documents.iloc[:,2]\n",
        "type(phrase)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyWS5v_mYe29",
        "outputId": "3664ae4c-2a5e-4e08-effd-bfbd156586bb"
      },
      "source": [
        "phrase"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         A series of escapades demonstrating the adage ...\n",
              "1         A series of escapades demonstrating the adage ...\n",
              "2                                                  A series\n",
              "3                                                         A\n",
              "4                                                    series\n",
              "                                ...                        \n",
              "156055                                            Hearst 's\n",
              "156056                            forced avuncular chortles\n",
              "156057                                   avuncular chortles\n",
              "156058                                            avuncular\n",
              "156059                                             chortles\n",
              "Name: Phrase, Length: 156060, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE3GR0wRYe2-",
        "outputId": "bfb9c80d-204e-4d90-b001-41e8c7f2093f"
      },
      "source": [
        "test_phrase"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        An intermittently pleasing but mostly routine ...\n",
              "1        An intermittently pleasing but mostly routine ...\n",
              "2                                                       An\n",
              "3        intermittently pleasing but mostly routine effort\n",
              "4               intermittently pleasing but mostly routine\n",
              "                               ...                        \n",
              "66287               A long-winded , predictable scenario .\n",
              "66288                 A long-winded , predictable scenario\n",
              "66289                                      A long-winded ,\n",
              "66290                                        A long-winded\n",
              "66291                                 predictable scenario\n",
              "Name: Phrase, Length: 66292, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "h-Z-1kMyYe2-",
        "outputId": "16218b6e-d367-44a5-abff-a21977b93d36"
      },
      "source": [
        "phrase[0]\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UmCL_STXYe2_",
        "outputId": "c421b3df-389f-4d86-9bcb-90afa415f54e"
      },
      "source": [
        "test_phrase[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'An intermittently pleasing but mostly routine effort .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-kVEQ-uYe2_",
        "outputId": "d7a6d2db-2b98-4fbc-9037-752d84a392be"
      },
      "source": [
        "y=training_documents.iloc[:,3]\n",
        "y"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1\n",
              "1         2\n",
              "2         2\n",
              "3         2\n",
              "4         2\n",
              "         ..\n",
              "156055    2\n",
              "156056    1\n",
              "156057    3\n",
              "156058    2\n",
              "156059    2\n",
              "Name: Sentiment, Length: 156060, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHfcTn-JYe3A",
        "outputId": "a295a945-e696-4318-fe00-35c1eb2dc197"
      },
      "source": [
        "y=y.values\n",
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, ..., 3, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1yshm4LYe3A"
      },
      "source": [
        "def get_simple_pos(tag) :\n",
        "    if tag.startswith('J') :\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V') :\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N') :\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R') :\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze4oOhcbYe3A",
        "outputId": "fa6e9532-f4de-40e5-9fb7-dcf2fdc23240"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stops = set(stopwords.words('english'))\n",
        "import string\n",
        "punctuations = list(string.punctuation)\n",
        "stops.update(punctuations)\n",
        "stops"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krfu8lX-Ye3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c88ed3-fae4-4dbd-b56c-ba43440c07d8"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "#cleaning\n",
        "def clean_review(review) :\n",
        "    words = word_tokenize(review)\n",
        "    output_words = []\n",
        "    for w in words :\n",
        "        if w.lower() not in stops :\n",
        "            pos = pos_tag([w])\n",
        "            clean_word = lemmatizer.lemmatize(w,pos = get_simple_pos(pos[0][1]))\n",
        "            output_words.append(clean_word.lower())\n",
        "    #print(output_words)\n",
        "    return \" \".join(output_words)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "_1DrmqO7Ye3B",
        "outputId": "5028b607-64ce-4aa2-daf1-8b2ac90936fe"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "phrase=phrase.values\n",
        "phrase = [clean_review(review) for review in phrase]\n",
        "phrase[0]\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'series escapade demonstrate adage good goose also good gander occasionally amuses none amount much story'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wc4EsRYZRl5"
      },
      "source": [
        "count_vec = CountVectorizer(max_df = 0.80,min_df = 0.0005)\n",
        "x_train = count_vec.fit_transform(phrase)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjVcW1B-Ye3C",
        "outputId": "76c75686-51c9-454f-a743-8d7ade8e54bc"
      },
      "source": [
        "x_train_split,x_test_split,y_train_split,y_test_split = train_test_split(x_train,y,random_state = 0,test_size = 0.2)\n",
        "x_train.todense()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA0eYOlNYe3C",
        "outputId": "62d0ba52-b1ee-46d6-8277-0273c8f1cb09"
      },
      "source": [
        "len(count_vec.get_feature_names())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1510"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W3E72VIuhOE"
      },
      "source": [
        "pickle.dump(count_vec,open('count_vec.pkl','wb'))\n",
        "count_vec=pickle.load(open('count_vec.pkl','rb'))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXTCvTwFYe3D",
        "outputId": "be81002a-7ccb-45e9-a744-41494e7889b8"
      },
      "source": [
        "print(x_train_split.shape)\n",
        "print(y_train_split.shape)\n",
        "print(x_test_split.shape)\n",
        "print(y_test_split.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124848, 1510)\n",
            "(124848,)\n",
            "(31212, 1510)\n",
            "(31212,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1TRk4xBXmEI"
      },
      "source": [
        "x_test = count_vec.transform(test_phrase)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiz208S-Ye3D",
        "outputId": "96482719-b586-4468-ccf8-7303d081ecb4"
      },
      "source": [
        "#Logistic_regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train_split,y_train_split)\n",
        "print(lr.score(x_test_split,y_test_split))\n",
        "y_pred1 = lr.predict(x_test)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6002178649237473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp6XTxOXYe3G",
        "outputId": "68673470-cab2-4b81-a70b-e70a3b885524"
      },
      "source": [
        "#SVC classifier\n",
        "svc = SVC(kernel = 'rbf')\n",
        "svc.fit(x_train_split,y_train_split)\n",
        "print(svc.score(x_test_split,y_test_split))\n",
        "y_pred = svc.predict(x_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6327694476483404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE5uGpHPz_Uj"
      },
      "source": [
        "pickle.dump(svc,open('model.pkl','wb'))\n",
        "model=pickle.load(open('model.pkl','rb'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhG6DUyEYe3E",
        "outputId": "fbd9cf00-e113-4015-aaae-25f78897db7b"
      },
      "source": [
        "#random forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train_split,y_train_split)\n",
        "print(rf.score(x_test_split,y_test_split))\n",
        "y_pred2 = rf.predict(x_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6258490324234269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV4t_evzYe3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ba42f9-78f2-489e-a7ba-36406830567b"
      },
      "source": [
        "#KNN\n",
        "clf = KNeighborsClassifier()\n",
        "clf.fit(x_train_split , y_train_split)\n",
        "print(clf.score(x_test_split,y_test_split))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5979110598487761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-vWjVzkYe3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f999ea83-c885-462d-c726-617a4d4580fe"
      },
      "source": [
        "#Naive_Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train_split,y_train_split)\n",
        "print(nb.score(x_test_split,y_test_split))\n",
        "y_pred3 = nb.predict(x_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5881391772395232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgEoM3p5Ye3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9acf97-7d48-41a8-bc6d-a5a28a6411c8"
      },
      "source": [
        "import xgboost as xgb\n",
        "#XGBoost\n",
        "model=xgb.XGBClassifier()\n",
        "model\n",
        "model.fit(x_train_split,y_train_split)\n",
        "print(model.score(x_test_split,y_test_split))\n",
        "y_pred1 = model.predict(x_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5274573881840318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr1SATG4Ye3H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}